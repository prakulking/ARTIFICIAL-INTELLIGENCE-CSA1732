import numpy as np

class DecisionTree:
    def __init__(self, min_samples_split=2, max_depth=5):
        self.min_samples_split = min_samples_split
        self.max_depth = max_depth
        self.tree = None

    def fit(self, X, y):
        dataset = np.column_stack((X, y))
        self.tree = self._build_tree(dataset)

    def predict(self, X):
        return [self._predict(inputs, self.tree) for inputs in X]

    def _build_tree(self, dataset, depth=0):
        X, y = dataset[:, :-1], dataset[:, -1]
        num_samples, num_features = X.shape

        if num_samples >= self.min_samples_split and depth <= self.max_depth:
            best_split = self._get_best_split(dataset, num_features)
            if best_split["gini"] < float("inf"):
                left_subtree = self._build_tree(best_split["dataset_left"], depth + 1)
                right_subtree = self._build_tree(best_split["dataset_right"], depth + 1)
                return Node(best_split["feature_index"], best_split["threshold"], left_subtree, right_subtree)

        leaf_value = self._calculate_leaf_value(y)
        return Node(value=leaf_value)

    def _get_best_split(self, dataset, num_features):
        best_split = {}
        min_gini = float("inf")

        for feature_index in range(num_features):
            feature_values = dataset[:, feature_index]
            possible_thresholds = np.unique(feature_values)
            for threshold in possible_thresholds:
                dataset_left, dataset_right = self._split(dataset, feature_index, threshold)
                if len(dataset_left) > 0 and len(dataset_right) > 0:
                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]
                    current_gini = self._calculate_gini_index(y, left_y, right_y)

                    if current_gini < min_gini:
                        min_gini = current_gini
                        best_split["feature_index"] = feature_index
                        best_split["threshold"] = threshold
                        best_split["dataset_left"] = dataset_left
                        best_split["dataset_right"] = dataset_right
                        best_split["gini"] = current_gini

        return best_split

    def _split(self, dataset, feature_index, threshold):
        dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])
        dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])
        return dataset_left, dataset_right

    def _calculate_gini_index(self, y, left_y, right_y):
        weight_left = len(left_y) / len(y)
        weight_right = len(right_y) / len(y)
        gini_left = 1 - sum((np.sum(left_y == c) / len(left_y)) ** 2 for c in np.unique(left_y))
        gini_right = 1 - sum((np.sum(right_y == c) / len(right_y)) ** 2 for c in np.unique(right_y))
        gini_index = weight_left * gini_left + weight_right * gini_right
        return gini_index

    def _calculate_leaf_value(self, y):
        return np.bincount(y).argmax()

    def _predict(self, inputs, tree):
        if tree.value is not None:
            return tree.value
        feature_value = inputs[tree.feature_index]
        if feature_value <= tree.threshold:
            return self._predict(inputs, tree.left)
        else:
            return self._predict(inputs, tree.right)


class Node:
    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):
        self.feature_index = feature_index
        self.threshold = threshold
        self.left = left
        self.right = right
        self.value = value


# Example usage
if __name__ == "__main__":
    # Training data (X) and labels (y)
    X = np.array([[2, 3],
                  [10, 15],
                  [3, 6],
                  [10, 12],
                  [6, 8],
                  [8, 10]])
    y = np.array([0, 1, 0, 1, 0, 1])

    # Create and train the decision tree
    tree = DecisionTree(min_samples_split=2, max_depth=3)
    tree.fit(X, y)

    # Make predictions
    X_test = np.array([[3, 5], [9, 14]])
    predictions = tree.predict(X_test)
    print(f"Predictions: {predictions}")
